{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Data-Mining-Versuch-Mobile-User-Analysis-and-Gender-Age-Group-Prediction\" data-toc-modified-id=\"Data-Mining-Versuch-Mobile-User-Analysis-and-Gender-Age-Group-Prediction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Mining Versuch Mobile User Analysis and Gender-Age-Group Prediction</a></div><div class=\"lev1 toc-item\"><a href=\"#Einführung\" data-toc-modified-id=\"Einführung-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Einführung</a></div><div class=\"lev2 toc-item\"><a href=\"#Kurzbeschreibung:\" data-toc-modified-id=\"Kurzbeschreibung:-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Kurzbeschreibung:</a></div><div class=\"lev2 toc-item\"><a href=\"#Lernziele:\" data-toc-modified-id=\"Lernziele:-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Lernziele:</a></div><div class=\"lev2 toc-item\"><a href=\"#Aufgaben-zur-Vorbereitung\" data-toc-modified-id=\"Aufgaben-zur-Vorbereitung-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Aufgaben zur Vorbereitung</a></div><div class=\"lev1 toc-item\"><a href=\"#Durchführung\" data-toc-modified-id=\"Durchführung-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Durchführung</a></div><div class=\"lev2 toc-item\"><a href=\"#Datenzugriff\" data-toc-modified-id=\"Datenzugriff-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Datenzugriff</a></div><div class=\"lev2 toc-item\"><a href=\"#Deskriptive-Statistik\" data-toc-modified-id=\"Deskriptive-Statistik-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Deskriptive Statistik</a></div><div class=\"lev3 toc-item\"><a href=\"#Verteilung-der-User-über-die-Gender-Age-Gruppen\" data-toc-modified-id=\"Verteilung-der-User-über-die-Gender-Age-Gruppen-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Verteilung der User über die Gender-Age-Gruppen</a></div><div class=\"lev3 toc-item\"><a href=\"#Verteilung-der-User-über-die-Smartphone-Marken\" data-toc-modified-id=\"Verteilung-der-User-über-die-Smartphone-Marken-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Verteilung der User über die Smartphone-Marken</a></div><div class=\"lev2 toc-item\"><a href=\"#Spatio-Temporale-Analyse-des-Verhaltens-einzelner-User\" data-toc-modified-id=\"Spatio-Temporale-Analyse-des-Verhaltens-einzelner-User-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Spatio-Temporale Analyse des Verhaltens einzelner User</a></div><div class=\"lev1 toc-item\"><a href=\"#Feature-Extraction\" data-toc-modified-id=\"Feature-Extraction-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Feature Extraction</a></div><div class=\"lev1 toc-item\"><a href=\"#Gender-Age-Group-Prediction\" data-toc-modified-id=\"Gender-Age-Group-Prediction-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Gender-Age-Group Prediction</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Mobile User Analysis and Gender-Age-Group Prediction\n",
    "* Autor: Prof. Dr. Johannes Maucher\n",
    "* Datum: 04.10.2016\n",
    "* [Download des Jupyter Notebooks (.ipynb)](Data Mining Praktikum.ipynb) Klick auf _Ziel speichern unter_. Im Verzeichnis, in dem das Notebook abgelegt wurde, Konsole öffnen und dort _jupyter notebook_ eingeben.\n",
    "\n",
    "[Übersicht Ipython Notebooks im Data Mining Praktikum](Data Mining Praktikum.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung\n",
    "\n",
    "## Kurzbeschreibung:\n",
    "\n",
    "In diesem Versuch werden die im Rahmen eines Kaggle-Contest [von _TalkingData_ bereitgestellten Daten](https://www.kaggle.com/c/talkingdata-mobile-user-demographics/data) analysiert. Die Daten enthalten für eine große Menge chinesischer User, Angaben zur Marke und Modell des Smartphones und zu den installierten und aktiven Apps. Ziel ist es aus den zur Verfügung stehenden Trainingsdaten ein Modell zu erlernen, das die Klassifikation der User in die jeweilige Gender-Age-Gruppe erlaubt. Für die Lösung dieser Aufgabe müssen sämtliche Schritte der Data Mining Prozesskette implementiert werden:\n",
    "\n",
    "1. Datenbeschaffung und Zugriff\n",
    "2. Datenauswahl: Welche der vorhandenen Daten sind für die gegebene Aufgabe tatsächlich relevant\n",
    "3. Datenbereinigung: Wie wird mit fehlenden und fehlerhaften Daten umgegangen?\n",
    "4. Datentransformation: Wie können aus den vorhandenen Daten informative Mermale gewonnen werden?\n",
    "5. Modellbildung: Unüberwachtes oder überwachtes erlernen eines Modells; Clustering-, Klassifikations- oder Regressionsmodell.\n",
    "6. Evaluation, Visualisierung und Interpretation der Daten/Ergebnisse\n",
    "\n",
    "## Lernziele:\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* Zugriff auf Daten in .csv Files\n",
    "* Zugriff auf Daten in SQLite Files\n",
    "* Statistische Analyse und Visualisierung von Daten\n",
    "* Implementierung der oben genannten Data Mining Prozessschritte, insbesondere:\n",
    "\n",
    "    * Feature-Engineering: Berechnung von für die gegebene Aufgabe relevanter Daten aus Rohdaten\n",
    "    * Clustering (unüberwachtes Lernen) \n",
    "    * Klassifikation/Prädiktion (überwachtes Lernen) mit verschiedenen Machine Learning Verfahren\n",
    "    * Evaluation von Klassifikationsverfahren\n",
    "\n",
    "## Aufgaben zur Vorbereitung\n",
    "\n",
    "1. Laden Sie die Daten entweder vom Skripteserver oder direkt von [Kaggle](https://www.kaggle.com/c/talkingdata-mobile-user-demographics/data) herunter und versuchen Sie die Daten anhand dieser [Beschreibung](https://www.kaggle.com/c/talkingdata-mobile-user-demographics/data) zu verstehen.\n",
    "2. In diesem Versuch soll die Gender-Age-Group von Smartphone-Usern vorhergesagt werden. Überlegen Sie sich welche der vorhandenen Daten für diese Vorhersage relevant sein könnten.\n",
    "3. Für die Vorhersage kann ein beliebiger Klassifikationsalgorithmus aus dem Bereich des überwachten Lernens eingesetzt werden. Das Prinzip des überwachten Lernens und das entsprechende Testen des gelernten Modells ist in der unten aufgeführten Abbildung dargestellt. Machen Sie sich mit diesem Prinzip vertraut.\n",
    "\n",
    "4. Für das überwachte Lernen sind gelabelte Daten (Soll-Ausgabe) notwendig. In diesem Versuch ist die Ausgabe die Gender-Age-Group der User. Im File *gender\\_age\\_train.csv* ist für 74645 User (devices) die zugehörigen Gender-Age-Group angegeben. Die Menge aller gelabelten Daten muss für die Modellvalidierung in disjunkte Trainings- und Testpartitionen unterteilt werden. In diesem Versuch kommt sowohl eine einfache Partitionierung in Trainings- und Testdaten als auch eine Kreuzvalidierung zum Einsatz ([KI-Vorlesung](https://www.mi.hdm-stuttgart.de/mib/studium/intern/skripteserver/skripte/Einfuehrung_Kuenstliche_Intelligenz/WS1516/06_PartLernen1.pdf)). Machen Sie sich mit dem Prinzip der Kreuzvalidierung (Abbildung unten) vertraut.\n",
    "\n",
    "5. Den meisten Machine Learning-Algorithmen können kategoriale Parameter nicht direkt übergeben werden. Diese Parameter werden typisch *One-Hot* encodiert. Machen Sie sich mit diesem Prinzip vertraut.\n",
    "\n",
    "6. In diesem Versuch soll ein Multilayer-Perzeptron (MLP) als Klassifikator eingesetzt werden. Machen Sie sich mit dem MLP vertraut. [KI-Vorlesung](https://www.mi.hdm-stuttgart.de/mib/studium/intern/skripteserver/skripte/Einfuehrung_Kuenstliche_Intelligenz/WS1516/09_PartLernen4.pdf), [MLP in Scikit-Learn](http://scikit-learn.org/stable/modules/neural_networks_supervised.html).\n",
    "\n",
    "**Prinzip überwachtes Lernen und Validierung:**\n",
    "![Prinzip überwachtes Lernen](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining//Bilder/SupervisedLarningSchemaValidation.png \"Überwachtes Lernen Schema\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Prinzip der 10-fachen Kreuzvalidierung:**\n",
    "\n",
    "![Kreuzvalidierung](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining//Bilder/CrossValidation.jpg \"Cross-Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durchführung\n",
    "## Datenzugriff\n",
    "Die Daten sind in insgesamt 7 .csv Files organisiert (das File sample_submission.csv wird nicht benötigt). Die einzelnen .csv Dateien sind z.T. sehr groß. In diesem Fall bietet es sich an, nicht das ganze File in einen Pandas-Dataframe zu laden, sondern das .csv-File zunächst in eine Datenbank zu schreiben und dann auf diese dediziert zuzugreifen. \n",
    "\n",
    "_Tipp:_ Mit der auf dem Skripteserver bereitgestellten Datei _brandMap.txt_, können die chinesischen Schriftzeichen in den Markennamen übersetzt werden.\n",
    "\n",
    "**Aufgaben:**\n",
    "\n",
    "1.Lesen Sie jedes der .csv Files in chunks von jeweils ca. 20000 Zeilen in einen Pandas Dataframe ein und schreiben Sie die Daten chunk für chunk in eine SQLite Database. Für das Einlesen ist die Pandas-Methode [read_csv()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) mit dem Parameter _chunksize_ zu verwenden. Für das schreiben der Daten aus dem Pandas Dataframe in die SQLite Datenbank ist die Pandas-Methode [to_sql()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html) zu verwenden. Für jedes .csv File soll in der SQLite-DB eine eigene Tabelle angelegt werden. Als DB-connector soll eine engine-Instanz des _SQLAlchemy_-Pakets mit der Methode create\\_engine() angelegt werden. Siehe z.B. [SQLAlchemy Doku](http://docs.sqlalchemy.org/en/latest/core/engines.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "disk_engine = create_engine('sqlite:///age_gender_data.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Adding Table app_events\n",
      "app_eventsAdded\n",
      "-> Adding Table app_labels\n",
      "app_labelsAdded\n",
      "-> Adding Table events\n",
      "eventsAdded\n",
      "-> Adding Table gender_age_test\n",
      "gender_age_testAdded\n",
      "-> Adding Table gender_age_train\n",
      "gender_age_trainAdded\n",
      "-> Adding Table label_categories\n",
      "label_categoriesAdded\n",
      "-> Adding Table phone_brand_device_model\n",
      "phone_brand_device_modelAdded\n"
     ]
    }
   ],
   "source": [
    "def create_table (file):\n",
    "  filepath = './data/' + file\n",
    "  tablename = file[:-4]\n",
    "  index_start = 1\n",
    "\n",
    "  for data_chunk in pd.read_csv(filepath, sep=',', encoding='utf-8',\n",
    "                                chunksize=20000, iterator=True):\n",
    "    data_chunk.index += index_start\n",
    "    data_chunk.to_sql(tablename, disk_engine, if_exists='append')\n",
    "    index_start = data_chunk.index[-1] + 1\n",
    "\n",
    "for file in listdir('./data'):\n",
    "  if file.endswith('.csv'):\n",
    "    print '-> Adding Table ' + file[:-4]\n",
    "    create_table(file)\n",
    "    print file[:-4] + 'Added'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Nachdem alle Tabellen der DB angelegt sind, sollen aus jeder Tabelle die ersten 10 Zeilen mit der Pandas Methode [read_sql_query()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_query.html) abgefragt und angezeigt werden. Ausserdem ist für jede Tabelle die Größe (Anzahl der Zeilen) auszugeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: app_events\n",
      "   index  event_id               app_id  is_installed  is_active\n",
      "0      1         2  5927333115845830913             1          1\n",
      "1      2         2 -5720078949152207372             1          0\n",
      "2      3         2 -1633887856876571208             1          0\n",
      "3      4         2  -653184325010919369             1          1\n",
      "4      5         2  8693964245073640147             1          1\n",
      "5      6         2  4775896950989639373             1          1\n",
      "6      7         2 -8022267440849930066             1          0\n",
      "7      8         2  9112463267739110219             1          0\n",
      "8      9         2 -3725672010020973973             1          0\n",
      "9     10         2  7167114343576723123             1          1\n",
      "Rows: [32473067]\n",
      "\n",
      "Table: app_labels\n",
      "   index               app_id  label_id\n",
      "0      1  7324884708820027918       251\n",
      "1      2 -4494216993218550286       251\n",
      "2      3  6058196446775239644       406\n",
      "3      4  6058196446775239644       407\n",
      "4      5  8694625920731541625       406\n",
      "5      6  8694625920731541625       407\n",
      "6      7  1977658975649789753       406\n",
      "7      8  1977658975649789753       407\n",
      "8      9  7311663864768030840       256\n",
      "9     10  5902120154267999338       256\n",
      "Rows: [459943]\n",
      "\n",
      "Table: events\n",
      "   index  event_id            device_id            timestamp  longitude  \\\n",
      "0      1         1    29182687948017175  2016-05-01 00:55:25     121.38   \n",
      "1      2         2 -6401643145415154744  2016-05-01 00:54:12     103.65   \n",
      "2      3         3 -4833982096941402721  2016-05-01 00:08:05     106.60   \n",
      "3      4         4 -6815121365017318426  2016-05-01 00:06:40     104.27   \n",
      "4      5         5 -5373797595892518570  2016-05-01 00:07:18     115.88   \n",
      "5      6         6  1476664663289716375  2016-05-01 00:27:21       0.00   \n",
      "6      7         7  5990807147117726237  2016-05-01 00:15:13     113.73   \n",
      "7      8         8  1782450055857303792  2016-05-01 00:15:35     113.94   \n",
      "8      9         9 -2073340001552902943  2016-05-01 00:15:33       0.00   \n",
      "9     10        10 -8195816569128397698  2016-05-01 00:41:31     119.34   \n",
      "\n",
      "   latitude  \n",
      "0     31.24  \n",
      "1     30.97  \n",
      "2     29.70  \n",
      "3     23.28  \n",
      "4     28.66  \n",
      "5      0.00  \n",
      "6     23.00  \n",
      "7     34.70  \n",
      "8      0.00  \n",
      "9     26.04  \n",
      "Rows: [3252950]\n",
      "\n",
      "Table: gender_age_test\n",
      "   index            device_id\n",
      "0      1  1002079943728939269\n",
      "1      2 -1547860181818787117\n",
      "2      3  7374582448058474277\n",
      "3      4 -6220210354783429585\n",
      "4      5 -5893464122623104785\n",
      "5      6 -7560708697029818408\n",
      "6      7   289797889702373958\n",
      "7      8  -402874006399730161\n",
      "8      9  5751283639860028129\n",
      "9     10  -848943298935149395\n",
      "Rows: [112071]\n",
      "\n",
      "Table: gender_age_train\n",
      "   index            device_id gender  age   group\n",
      "0      1 -8076087639492063270      M   35  M32-38\n",
      "1      2 -2897161552818060146      M   35  M32-38\n",
      "2      3 -8260683887967679142      M   35  M32-38\n",
      "3      4 -4938849341048082022      M   30  M29-31\n",
      "4      5   245133531816851882      M   30  M29-31\n",
      "5      6 -1297074871525174196      F   24  F24-26\n",
      "6      7   236877999787307864      M   36  M32-38\n",
      "7      8 -8098239495777311881      M   38  M32-38\n",
      "8      9   176515041953473526      M   33  M32-38\n",
      "9     10  1596610250680140042      F   36  F33-42\n",
      "Rows: [74645]\n",
      "\n",
      "Table: label_categories\n",
      "   index  label_id              category\n",
      "0      1         1                  None\n",
      "1      2         2        game-game type\n",
      "2      3         3      game-Game themes\n",
      "3      4         4        game-Art Style\n",
      "4      5         5     game-Leisure time\n",
      "5      6         6   game-Cutting things\n",
      "6      7         7    game-Finding fault\n",
      "7      8         8  game-stress reliever\n",
      "8      9         9              game-pet\n",
      "9     10        10           game-Answer\n",
      "Rows: [930]\n",
      "\n",
      "Table: phone_brand_device_model\n",
      "   index            device_id phone_brand   device_model\n",
      "0      1 -8890648629457979026          小米             红米\n",
      "1      2  1277779817574759137          小米           MI 2\n",
      "2      3  5137427614288105724          三星      Galaxy S4\n",
      "3      4  3669464369358936369       SUGAR           时尚手机\n",
      "4      5 -5019277647504317457          三星  Galaxy Note 2\n",
      "5      6  3238009352149731868          华为           Mate\n",
      "6      7 -3883532755183027260          小米          MI 2S\n",
      "7      8 -2972199645857147708          华为          G610S\n",
      "8      9 -5827952925479472594          小米    MI One Plus\n",
      "9     10 -8262508968076336275        vivo            S7I\n",
      "Rows: [187245]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_infos(table):\n",
    "    data = pd.read_sql_query('SELECT * FROM ' + table + ' LIMIT 10', disk_engine)\n",
    "    print data\n",
    "    print 'Rows: ' + str(pd.read_sql_query('SELECT Count(*) FROM ' + table, disk_engine).values[0])\n",
    "\n",
    "for table in listdir('./data'):\n",
    "    if table.endswith('.csv'):\n",
    "        print 'Table: ' + table[:-4]\n",
    "        get_infos(table[:-4])\n",
    "        print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Wie viele verschiedene devices befinden sich in der Tabelle, welche die Daten aus gender\\_age\\_train.csv enthält?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Devices: 74645\n"
     ]
    }
   ],
   "source": [
    "num_of_devices = pd.read_sql_query('SELECT DISTINCT device_id FROM gender_age_train', disk_engine)\n",
    "print 'Number of Devices: ' + str(len(num_of_devices.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Wie viele verschiedene devices befinden sich in der Tabelle, welche die Daten aus events.csv enthält?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Devices: 60865\n"
     ]
    }
   ],
   "source": [
    "num_of_devices = pd.read_sql_query('SELECT DISTINCT device_id FROM events', disk_engine)\n",
    "print 'Number of Devices: ' + str(len(num_of_devices.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Wie viele verschiedene devices kommen in beiden dieser Tabellen vor? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 112201\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "num1_of_devices = pd.read_sql_query('SELECT DISTINCT device_id FROM gender_age_train', disk_engine)\n",
    "num2_of_devices = pd.read_sql_query('SELECT DISTINCT device_id FROM events', disk_engine)\n",
    "\n",
    "concat_num = pd.concat([num1_of_devices, num2_of_devices])\n",
    "\n",
    "print 'Number of devices: ' + str(len(set(numpy.ndarray.flatten(concat_num.values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Deskriptive Statistik\n",
    "\n",
    "In der obigen Teilaufgabe sollte die Schnittstelle zwischen Pandas Dataframes und Datenbanken (hier SQLite) demonstriert werden. Diese Art von Datenhandling eignet sich besonders im Fall sehr großer Datenmengen, die nicht im Arbeitsspeicher gehalten werden können. Die Dateien in diesem Versuch sind tatsächlich nicht so groß, dass sie nicht als ganzes in Pandas-Dataframes geladen werden könnten. In allen folgenden Teilversuchen ist Ihnen freigestellt, ob Sie mit der Datenbank-Variante oder der in-memory Variante (alle Daten im Pandas-Dataframe) arbeiten.\n",
    "\n",
    "### Verteilung der User über die Gender-Age-Gruppen\n",
    "\n",
    "Die Menge aller User wird in 12 verschiedene Gender-Age-Groups unterteilt. Bestimmen Sie die Verteilung der User in der gender\\_age\\_train-Tabelle über diese 12 Gruppen und viusalisieren Sie diese Verteilung in einem [Matplolib Bar Chart](http://matplotlib.org/api/pyplot_api.html). \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verteilung der User über die Smartphone-Marken\n",
    "\n",
    "1.Bestimmen Sie die Anzahl der verschiedenen Devices und die Anzahl der verschiedenen Marken in der Tabelle *phone\\_brand\\_device\\_model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of devices: [186716]\n",
      "Num of brands: [130]\n"
     ]
    }
   ],
   "source": [
    "num_of_devices = pd.read_sql_query('SELECT COUNT(DISTINCT device_id) FROM phone_brand_device_model', disk_engine).values[0]\n",
    "num_of_brands = pd.read_sql_query('SELECT COUNT(DISTINCT phone_brand) FROM phone_brand_device_model', disk_engine).values[0]\n",
    "\n",
    "print 'Num of devices: ' + str(num_of_devices)\n",
    "print 'Num of brands: ' + str(num_of_brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Fügen Sie dem Pandas Dataframe mit der *gender_age_train*-Tabelle eine Spalte _brand_ hinzu und schreiben Sie in diese Spalte den Markennamen des zur jeweiligen Zeile gehörenden Device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index            device_id gender  age   group phone_brand\n",
      "0          1 -8076087639492063270      M   35  M32-38      xiaomi\n",
      "1          2 -2897161552818060146      M   35  M32-38      xiaomi\n",
      "2          3 -8260683887967679142      M   35  M32-38      xiaomi\n",
      "3          4 -4938849341048082022      M   30  M29-31      xiaomi\n",
      "4          5   245133531816851882      M   30  M29-31      xiaomi\n",
      "5          6 -1297074871525174196      F   24  F24-26        OPPO\n",
      "6          7   236877999787307864      M   36  M32-38     coolpad\n",
      "7          8 -8098239495777311881      M   38  M32-38      xiaomi\n",
      "8          9   176515041953473526      M   33  M32-38        vivo\n",
      "9         10  1596610250680140042      F   36  F33-42     samsung\n",
      "10        11  9032155484127182494      M   31  M29-31      huawei\n",
      "11        12  7477216237379271436      F   37  F33-42      huawei\n",
      "12        13  2478205222798310601      F   28  F27-28     samsung\n",
      "13        14  6352067998666467520      M   32  M32-38      huawei\n",
      "14        15 -7605360767281960867      M   48    M39+     aiyouni\n",
      "15        16  1508636020748379883      F   28  F27-28      huawei\n",
      "16        17  4380872794486415327      M   38  M32-38      xiaomi\n",
      "17        18 -1039701474753771322      M   38  M32-38      xiaomi\n",
      "18        19 -6876541075223249434      M   75    M39+       meizu\n",
      "19        20  6287938418661076759      M   33  M32-38      xiaomi\n",
      "20        21 -6029676723224952628      F   39  F33-42     samsung\n",
      "21        22  8026504930081700361      M   25  M23-26      xiaomi\n",
      "22        23  1118970699362079126      M   24  M23-26      huawei\n",
      "23        24 -7271319853104672050      M   27  M27-28     samsung\n",
      "24        25 -9216966316587614491      M   29  M29-31      xiaomi\n",
      "25        26 -4913644674161904021      M   34  M32-38     samsung\n",
      "26        27  2313145512701915151      M   34  M32-38     samsung\n",
      "27        28  4309468945717577632      F   36  F33-42     samsung\n",
      "28        29 -4547337748907986143      M   37  M32-38     samsung\n",
      "29        30 -7216269352973401877      M   37  M32-38     samsung\n",
      "...      ...                  ...    ...  ...     ...         ...\n",
      "74615  74616  7826033719277536366      M   28  M27-28      huawei\n",
      "74616  74617  8939634378631061484      M   31  M29-31         TCL\n",
      "74617  74618  1676125742207316285      F   28  F27-28        vivo\n",
      "74618  74619  2627933310180294504      M   31  M29-31     samsung\n",
      "74619  74620  7176422141809079294      M   23  M23-26      xiaomi\n",
      "74620  74621  -877731366874189491      M   22    M22-     coolpad\n",
      "74621  74622 -1324027033843938692      M   22    M22-     coolpad\n",
      "74622  74623 -3569962198902678507      F   59    F43+      huawei\n",
      "74623  74624  2032262288045492186      F   29  F29-32      xiaomi\n",
      "74624  74625 -6220019934264142137      M   29  M29-31     coolpad\n",
      "74625  74626 -4071460957162948519      F   27  F27-28      huawei\n",
      "74626  74627  8012242415081116163      F   30  F29-32      huawei\n",
      "74627  74628 -7513478293429751074      F   56    F43+      huawei\n",
      "74628  74629  2918022610076499795      M   26  M23-26      xiaomi\n",
      "74629  74630   442105793738318663      M   35  M32-38      xiaomi\n",
      "74630  74631 -2510601842775405069      F   22    F23-     samsung\n",
      "74631  74632 -2572857383593438598      F   21    F23-         zte\n",
      "74632  74633 -5804749754315732086      M   33  M32-38      xiaomi\n",
      "74633  74634 -4229815843211107303      M   53    M39+      xiaomi\n",
      "74634  74635 -8331157719771660970      M   53    M39+      xiaomi\n",
      "74635  74636  1728576663562073800      M   38  M32-38      lenovo\n",
      "74636  74637  8116314513428390753      M   25  M23-26         TCL\n",
      "74637  74638 -3539330294838027409      M   25  M23-26         TCL\n",
      "74638  74639  5645813107043557722      F   51    F43+      xiaomi\n",
      "74639  74640 -4752726726975186730      M   26  M23-26     samsung\n",
      "74640  74641  4682031842235089751      M   30  M29-31      xiaomi\n",
      "74641  74642 -9178703742877135986      M   30  M29-31      xiaomi\n",
      "74642  74643   180946546684162312      M   20    M22-      xiaomi\n",
      "74643  74644  1390702386071991851      M   37  M32-38      huawei\n",
      "74644  74645    89181010588227347      M   25  M23-26      xiaomi\n",
      "\n",
      "[74645 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "gender_age_train = pd.read_sql_query('SELECT * FROM gender_age_train', disk_engine)\n",
    "device_ids = [row[1] for row in gender_age_train.values]\n",
    "\n",
    "phone_brand_device_model = pd.read_sql_query('SELECT * FROM phone_brand_device_model', disk_engine)\n",
    "\n",
    "gender_age_train['phone_brand'] = [phone_brand_device_model.query('device_id==' + str(device_id)).values[0][2] for device_id in device_ids]\n",
    "\n",
    "print gender_age_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Schreiben Sie den um den Markennamen erweiterten Dataframe in ein File *gender\\_age\\_brand\\_train.csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_age_train.to_csv('./data/gender_age_brand_train.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Bestimmmen Sie mittels der Dataframe-Methode *value_counts()* die Anzahl der Devices pro Marke. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xiaomi     17299\n",
      "samsung    13669\n",
      "huawei     12960\n",
      "OPPO        5783\n",
      "vivo        5637\n",
      "meizu       4699\n",
      "coolpad     3339\n",
      "lenovo      2691\n",
      "gionee      1123\n",
      "HTC         1013\n",
      "zte          861\n",
      "lshi         757\n",
      "sony         715\n",
      "nubia        483\n",
      "LG           332\n",
      "ccmc         275\n",
      "TCL          220\n",
      "dowe         213\n",
      "hisense      204\n",
      "youmi        192\n",
      "hammer       191\n",
      "oneplus      174\n",
      "yuxin        170\n",
      "Ktouch       159\n",
      "奇酷           140\n",
      "moto         103\n",
      "酷比            67\n",
      "koobee        64\n",
      "asus          59\n",
      "meitu         57\n",
      "           ...  \n",
      "虾米             3\n",
      "百加             3\n",
      "PPTV           3\n",
      "欧奇             3\n",
      "desci          3\n",
      "惠普             2\n",
      "广信             2\n",
      "恒宇丰            2\n",
      "丰米             2\n",
      "瑞米             2\n",
      "本为             2\n",
      "唯比             2\n",
      "原点             1\n",
      "世纪天元           1\n",
      "pner           1\n",
      "鲜米             1\n",
      "优语             1\n",
      "欧乐酷            1\n",
      "天宏时代           1\n",
      "亚马逊            1\n",
      "西门子            1\n",
      "ZOYE           1\n",
      "大显             1\n",
      "mole           1\n",
      "飞利浦            1\n",
      "fs             1\n",
      "戴尔             1\n",
      "宝捷讯            1\n",
      "MIL            1\n",
      "凯利通            1\n",
      "Name: phone_brand, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print gender_age_train['phone_brand'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Stellen Sie diese Verteilung der Devices über die Marken für die 20 häufigsten Marken grafisch mit einem *Matplotlib-bar-chart dar.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xiaomi     17299\n",
      "samsung    13669\n",
      "huawei     12960\n",
      "OPPO        5783\n",
      "vivo        5637\n",
      "meizu       4699\n",
      "coolpad     3339\n",
      "lenovo      2691\n",
      "gionee      1123\n",
      "HTC         1013\n",
      "zte          861\n",
      "lshi         757\n",
      "sony         715\n",
      "nubia        483\n",
      "LG           332\n",
      "ccmc         275\n",
      "TCL          220\n",
      "dowe         213\n",
      "hisense      204\n",
      "youmi        192\n",
      "Name: phone_brand, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "most_used = gender_age_train['phone_brand'].value_counts()[:20]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "print most_used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Untersuchen Sie jetzt die Verteilung der Devices über die Marken pro Gender-Age-Group. Gibt es eine Korrelation zwischen Gender-Age-Group und Häufigkeit der Marken? Überlegen sie sich eine Visualisierung mit der eine derartige Korrelation bestätigt oder widerlegt werden kann. Implementieren Sie die Visualisierung und zeigen Sie anhand dieser Visualisierung mögliche Korrelationen zwischen Gender-Age-Group und Markenhäufigkeit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatio-Temporale Analyse des Verhaltens einzelner User\n",
    "\n",
    "1. Wählen Sie aus der *events*-Tabelle ein Device, für das mindestens 30 events mit zugewiesenen Geokordinaten vorliegen.\n",
    "2. Stellen Sie alle Aufenthaltsorte des zu diesem Device gehörenden Users in einer *gmaps-Heatmap* dar. Informationen hierzu finden Sie in der [gmaps-Doku]( https://github.com/pbugnion/gmaps). Für den Zugriff auf gmaps benötigen Sie einen Google-API-Key (siehe [gmaps authentication](http://jupyter-gmaps.readthedocs.io/en/latest/authentication.html))\n",
    "3. Clustern Sie die 2-dimensionalen Geodaten des ausgewählten Users mit dem [DBSCAN-Algorithmus von scikit-learn](http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html). Die Parameter des Algorithmus sind so zu wählen, dass wesentlich unterschiedliche Orte des Users in unterschiedlichen Clustern landen.\n",
    "4. Stellen Sie den zeitlichen Verlauf der Events des ausgewählten Users im unten dargestellten Stil visuell dar. Auf der horizontalen Achse ist die Zeit relativ zur Zeit des ersten Events in Sekunden dargestellt. Auf der vertikalen Achse ist die Anzahl der bisherigen Events des Users aufgetragen. Mit jedem Event wird der Wert auf der vertikalen Achse um 1 erhöht. Die Farbe der Marker im Graph gibt den Aufenthaltscluster an. Für jeden in der vorigen Teilaufgabe gefundenen Aufenthaltscluster wird eine unterschiedliche Farbe benutzt (Im Beispiel unten wurden nur 2 Cluster gefunden). Diskutieren Sie das Verhalten des Users anhand des Graphs.\n",
    "\n",
    "![Abbildung Zeitliches Auftreten der Events](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining//Bilder/tempbehave.PNG \"Events über der Zeit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gmaps\n",
    "import gmaps.datasets\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "disk_engine = create_engine('sqlite:///age_gender_data.db')\n",
    "gmaps.configure(api_key=\"AIzaSyClpaNzafIHGEzy8Uqs9p2NUwU-PK1qcSs\") # Your Google API key\n",
    "\n",
    "df = pd.read_sql_query('SELECT latitude, longitude FROM events WHERE device_id = \"3915082290673137129\"', disk_engine)\n",
    "\n",
    "points = zip(df.latitude, df.longitude)\n",
    "\n",
    "m = gmaps.Map()\n",
    "m.add_layer(gmaps.Heatmap(data=points))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named sklearn.cluster",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a9ee6bc2b491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named sklearn.cluster"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "db = DBSCAN(eps=0.001, min_samples=10).fit(points)\n",
    "\n",
    "display([{'point': point, 'cluster': db.labels_[i]} for (i, point) in enumerate(points)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anmerkung: In den vorigen Aufgaben war das Vorgehen relativ konkret vorgegeben. In den folgenden Aufgaben sind die Vorgaben bewußt knapp gehalten. Ihre Kreativität ist gefragt.\n",
    "\n",
    "1. Überlegen Sie sich aus welchen Merkmalen, die aus den vorhandenen Daten extrahiert werden können, möglichst gut die Gender-Age-Group vorhergesagt werden kann.\n",
    "2. Extahieren Sie diese Merkmale aus den Daten für möglichst viele (mindestens 20.000) User (devices) aus der Tabelle *gender_age_train*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender-Age-Group Prediction\n",
    "1. In der vorigen Aufgabe wurde für jeden User (device) ein Merkmalsvektor berechnet. Die Menge der Merkmalsvektoren aller User aus der Tabelle *gender_age_train* bildet die Eingabe-Matrix $X$ für die Klassifikationsalgorithmen. Die Soll-Ausgabe Vektor $y$ wird durch die *gender_age_group* der User gebildet. Bringen Sie die Matrix aller Eingabevektoren in eine Form, in der\n",
    "    * alle kategorialen Parameter *One-Hot*-encodiert sind [Scikit-Learn One-Hot-Encoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder).\n",
    "    * alle Merkmale eine Varianz von 1 aufweisen. Benützen Sie hierfür die [Scikit-Learn Methode scale](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale).\n",
    "2. Teilen Sie die Datensätze in $X$ und $y$ in eine Trainings- und eine Testpartition auf - im Verhältnis $3/4$ für Training, $1/4$ für Test. \n",
    "3. Trainieren Sie mit der Trainingspartition ein [Multilayer-Perzeptron](http://scikit-learn.org/stable/modules/neural_networks_supervised.html).\n",
    "4. Testen Sie das gelernte Modell mit der Testpartition. Für die Auswertung sollte die [Accurracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) und die [Confusion Matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) bestimmt werden. Finden Sie eine Parametereinstellung, die zu einer möglichst guten Accuracy führt. Interpretieren Sie die Confusion Matrix.\n",
    "5. Wenden Sie nun eine [5-fache Kreuzvalidierung](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) an und bestimmen Sie damit eine möglichst gute Parametereinstellung.\n",
    "6. Mit welchen Parametern erzielen Sie die beste Accurracy? Wie hoch ist diese dann? Diskutieren Sie das Ergebnis.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
